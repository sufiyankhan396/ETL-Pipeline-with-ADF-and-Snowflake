# ETL Pipeline: Azure Data Factory (ADF) & Snowflake  

## ğŸ“Œ Project Overview
This project implements an end-to-end **ETL (Extract, Transform, Load) pipeline** using **Azure Data Factory (ADF) and Snowflake**. It extracts customer order data from an **Azure SQL Database**, processes it in **Azure Blob Storage**, and loads it into **Snowflake** for analytics.

### ğŸš€ **Key Features**
- **Data Extraction:** Orders are extracted from an **Azure SQL Database**.
- **Data Loading:** Extracted data is temporarily stored in **Azure Blob Storage**.
- **Data Transformation & Load:** ADF processes and loads the data into **Snowflake**.
- **Performance Optimization:** Partitioning and indexing for faster analytics.
- **Data Validation:** Python script verifies the data in Snowflake.

---

## ğŸ“ **Project Structure**
```
ETL_Customer_Orders_ADF_Snowflake/
â”‚â”€â”€ README.md                      # Project documentation  
â”‚â”€â”€ data/  
â”‚   â”œâ”€â”€ sample_orders.csv           # Sample order data  
â”‚â”€â”€ adf_pipelines/  
â”‚   â”œâ”€â”€ export_orders_to_blob.json  # ADF pipeline: Export data to Blob Storage  
â”‚   â”œâ”€â”€ transform_load_snowflake.json # ADF pipeline: Load data into Snowflake  
â”‚â”€â”€ sql/  
â”‚   â”œâ”€â”€ create_snowflake_tables.sql # Snowflake table creation  
â”‚   â”œâ”€â”€ azure_sql_export.sql        # Export data from Azure SQL  
â”‚â”€â”€ src/  
â”‚   â”œâ”€â”€ config.py                   # Configuration settings  
â”‚   â”œâ”€â”€ validate_snowflake_data.py  # Python script to validate Snowflake data  
â”‚â”€â”€ docs/  
â”‚   â”œâ”€â”€ architecture_diagram.png    # High-level architecture diagram  
```

---

## ğŸ— **ETL Pipeline Architecture**
![ETL Architecture](docs/architecture_diagram.png)

1. **Extract**: ADF extracts customer order data from **Azure SQL Database**.
2. **Load to Blob**: Data is stored as a CSV file in **Azure Blob Storage**.
3. **Transform & Load**: ADF processes the data and loads it into **Snowflake**.
4. **Validation**: A Python script verifies the data in Snowflake.

---

## âš¡ **Technologies Used**
- **Azure Data Factory (ADF)** â†’ Orchestration  
- **Azure SQL Database** â†’ Source Database  
- **Azure Blob Storage** â†’ Staging Layer  
- **Snowflake** â†’ Data Warehouse  
- **Python** â†’ Data Validation  

---

## ğŸ“œ **Setup & Execution**
### 1ï¸âƒ£ **Clone the Repository**
```sh
git clone https://github.com/your-username/ETL_Customer_Orders_ADF_Snowflake.git
cd ETL_Customer_Orders_ADF_Snowflake
```

### 2ï¸âƒ£ **Setup Azure Resources**
- Create an **Azure SQL Database** and load sample data.
- Set up an **Azure Blob Storage** container.
- Deploy **ADF pipelines** from `adf_pipelines/`.

### 3ï¸âƒ£ **Run SQL Scripts**
#### âœ… **Create Snowflake Tables**
```sh
snowsql -q "SOURCE sql/create_snowflake_tables.sql"
```

#### âœ… **Export Data from Azure SQL**
Run the script `azure_sql_export.sql` to extract data.

### 4ï¸âƒ£ **Run Python Validation Script**
```sh
python src/validate_snowflake_data.py
```

---

## ğŸ“Š **Sample Data (`sample_orders.csv`)**
```csv
order_id,customer_id,order_date,amount
1,101,2024-01-10,500.00
2,102,2024-01-11,200.00
3,103,2024-01-12,300.00
```

---

## ğŸ¯ **Expected Output**
- Data successfully extracted from Azure SQL and stored in Blob.
- Data transformed and loaded into **Snowflake**.
- Validation script confirms the **correct record count**.

---

## ğŸ“Œ **Future Enhancements**
âœ… Implement **incremental data loading**  
âœ… Add **error handling & logging** in ADF  
âœ… Optimize **Snowflake queries** for performance  

---
